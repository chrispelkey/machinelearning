# PREDICT 422 Practical Machine Learning

# PREDICT 422-55
# Chris Pelkey
# FINAL PROJECT

# OBJECTIVE: A charitable organization wishes to develop a machine learning
# model to improve the cost-effectiveness of their direct marketing campaigns
# to previous donors.

# 1) Develop a classification model using data from the most recent campaign that
# can effectively capture likely donors so that the expected net profit is maximized.

# 2) Develop a prediction model to predict donation amounts for donors - the data
# for this will consist of the records for donors only.

# load the data
charity <- read.csv(file.choose()) # load the "charity.csv" file

# predictor transformations

charity.t <- charity
charity.t$avhv <- log(charity.t$avhv)
# add further transformations if desired
# for example, some statistical methods can struggle when predictors are highly skewed

# set up data for analysis

data.train <- charity.t[charity$part=="train",]
x.train <- data.train[,2:21]
c.train <- data.train[,22] # donr
n.train.c <- length(c.train) # 3984
y.train <- data.train[c.train==1,23] # damt for observations with donr=1
n.train.y <- length(y.train) # 1995

data.valid <- charity.t[charity$part=="valid",]
x.valid <- data.valid[,2:21]
c.valid <- data.valid[,22] # donr
n.valid.c <- length(c.valid) # 2018
y.valid <- data.valid[c.valid==1,23] # damt for observations with donr=1
n.valid.y <- length(y.valid) # 999

data.test <- charity.t[charity$part=="test",]
n.test <- dim(data.test)[1] # 2007
x.test <- data.test[,2:21]

x.train.mean <- apply(x.train, 2, mean)
x.train.sd <- apply(x.train, 2, sd)
x.train.std <- t((t(x.train)-x.train.mean)/x.train.sd) # standardize to have zero mean and unit sd
apply(x.train.std, 2, mean) # check zero mean
apply(x.train.std, 2, sd) # check unit sd
data.train.std.c <- data.frame(x.train.std, donr=c.train) # to classify donr
data.train.std.y <- data.frame(x.train.std[c.train==1,], damt=y.train) # to predict damt when donr=1

x.valid.std <- t((t(x.valid)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.valid.std.c <- data.frame(x.valid.std, donr=c.valid) # to classify donr
data.valid.std.y <- data.frame(x.valid.std[c.valid==1,], damt=y.valid) # to predict damt when donr=1

x.test.std <- t((t(x.test)-x.train.mean)/x.train.sd) # standardize using training mean and sd
data.test.std <- data.frame(x.test.std)

##### LOAD LIBRARIES FOR MODELING #####
library(glmnet)        #library for GLM, ridge regression & lasso
library(tree)          #library for classification trees
library(randomForest)  #library for random forests
library(leaps)         #library for subset selection (variable selection)
library(MASS)          #library for LDA modeling
library(e1071)         #library for SVM modeling
library(ISLR)          #library for logistic regression modeling
library(class)         #library for KNN model

##### EDA #####

# Pearson correlation
cov(data.train.std.c, method="pearson")

# Histograms of data
names=names(data.train[,-1])
classes=sapply(data.train,class)
for (name in names[classes == "integer"]){
  dev.new() 
  hist(data.train[,name], xlab=name,main="Charity Data Column Histogram")
}

# Summary of data points
summary(data.test.std)

# Best variables to use for DONR
set.seed(27)
var.charity.train = randomForest(donr~.,data=data.train.std.c,importance=TRUE,
                                  proximity=TRUE)
round(importance(var.charity.train), 2)
varImpPlot(var.charity.train)

# Best variables to use for DAMT
set.seed(27)
var.charity.train = randomForest(damt~.,data=data.train.std.y,importance=TRUE,
                                 proximity=TRUE)
round(importance(var.charity.train), 2)
varImpPlot(var.charity.train)


##### CLASSIFICATION MODELING ######

# linear discriminant analysis

model.lda1 <- lda(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat + 
                    avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif, 
                  data.train.std.c) # include additional terms on the fly using I()

# Note: strictly speaking, LDA should not be used with qualitative predictors,
# but in practice it often is if the goal is simply to find a good predictive model

post.valid.lda1 <- predict(model.lda1, data.valid.std.c)$posterior[,2] # n.valid.c post probs

# calculate ordered profit function using average donation = $14.50 and mailing cost = $2

profit.lda1 <- cumsum(14.5*c.valid[order(post.valid.lda1, decreasing=T)]-2)
plot(profit.lda1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.lda1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.lda1)) # report number of mailings and maximum profit
# 1329.0 11624.5

cutoff.lda1 <- sort(post.valid.lda1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.lda1 <- ifelse(post.valid.lda1>cutoff.lda1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.lda1, c.valid) # classification table
#               c.valid
#chat.valid.lda1   0   1
#              0 675  14
#              1 344 985
# check n.mail.valid = 344+985 = 1329
# check profit = 14.5*985-2*1329 = 11624.5

# logistic regression

model.log1 <- glm(donr ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + I(hinc^2) + genf + wrat + 
                    avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif, 
                  data.train.std.c, family=binomial("logit"))

post.valid.log1 <- predict(model.log1, data.valid.std.c, type="response") # n.valid post probs

# calculate ordered profit function using average donation = $14.50 and mailing cost = $2

profit.log1 <- cumsum(14.5*c.valid[order(post.valid.log1, decreasing=T)]-2)
plot(profit.log1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.log1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.log1)) # report number of mailings and maximum profit
# 1291.0 11642.5

cutoff.log1 <- sort(post.valid.log1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.log1 <- ifelse(post.valid.log1>cutoff.log1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.log1, c.valid) # classification table
#               c.valid
#chat.valid.log1   0   1
#              0 709  18
#              1 310 981
# check n.mail.valid = 310+981 = 1291
# check profit = 14.5*981-2*1291 = 11642.5

# Bagging
set.seed(27)
model.bag1=randomForest(donr~.,data=data.train.std.c,mtry=13,importance=TRUE)
model.bag1

post.valid.bag1 <- predict(model.bag1, data.valid.std.c, type="response")

model.bag2=randomForest(donr~.,data=data.train.std.c,mtry=6,importance=TRUE)
model.bag2

post.valid.bag2 <- predict(model.bag2, data.valid.std.c, type="response")

profit.bag1 <- cumsum(14.5*c.valid[order(post.valid.bag1, decreasing=T)]-2)
plot(profit.bag1) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.bag1) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.bag1)) # report number of mailings and maximum profit
# 1270.0 11742.5

cutoff.bag1 <- sort(post.valid.bag1, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.bag1 <- ifelse(post.valid.bag1>cutoff.bag1, 1, 0) # mail to everyone above the cutoff
table(chat.valid.bag1, c.valid) # classification table

#               c.valid
# chat.valid.bag1   0   1
#               0 734  14
#               1 285 985
# check n.mail.valid = 285+985 = 1270
# check profit = 14.5*985-2*1270 = 11742.5

profit.bag2 <- cumsum(14.5*c.valid[order(post.valid.bag2, decreasing=T)]-2)
plot(profit.bag2) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.bag2) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.bag2)) # report number of mailings and maximum profit
# 1265 11781.5

cutoff.bag2 <- sort(post.valid.bag2, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.bag2 <- ifelse(post.valid.bag2>cutoff.bag2, 1, 0) # mail to everyone above the cutoff
table(chat.valid.bag2, c.valid) # classification table

#                    c.valid
#   chat.valid.bag2   0   1
#                 0 769  23
#                 1 278  987
# check n.mail.valid = 278 + 987 = 1265
# check profit = 14.5*976-2*1267 = 11781.5

# Trees
set.seed(27)
require(tree)
tree.mail=tree(donr~.,data.train.std.c)
model.cv.tree=cv.tree(tree.mail)
model.cv.tree

model.tree=prune.tree(tree.mail,best=8)

post.valid.tree <- predict(model.tree, data.valid.std.c)

profit.tree <- cumsum(14.5*c.valid[order(post.valid.tree, decreasing=T)]-2)
plot(profit.tree) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.tree) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.tree)) # report number of mailings and maximum profit
# 1940  10576.5

cutoff.tree <- sort(post.valid.tree, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.tree <- ifelse(post.valid.tree>cutoff.tree, 1, 0) # mail to everyone above the cutoff
table(chat.valid.tree, c.valid) # classification table

# Boosting

library(gbm)
set.seed(27)
model.boost=gbm(donr~.,data=data.train.std.c,distribution="bernoulli",n.trees=5000,interaction.depth=4)
summary(model.boost)

post.valid.boost <- predict(model.boost, data.valid.std.c, n.trees=5000)

profit.boost <- cumsum(14.5*c.valid[order(post.valid.boost, decreasing=T)]-2)
plot(profit.boost) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.boost) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.boost)) # report number of mailings and maximum profit
# 1284  11845

cutoff.boost <- sort(post.valid.boost, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.boost <- ifelse(post.valid.boost>cutoff.boost, 1, 0) # mail to everyone above the cutoff
table(chat.valid.boost, c.valid) # classification table

#                    c.valid
#   chat.valid.bag2   0   1
#                 0 769  23
#                 1 278  987
# check n.mail.valid = 278 + 987 = 1284
# check profit = 14.5*976-2*1267 = 11845

# Boost #2

set.seed(27)
model.boost2=gbm(donr~.,data=data.train.std.c,distribution="bernoulli",n.trees=5000,interaction.depth=7)
summary(model.boost2)

post.valid.boost2 <- predict(model.boost2, data.valid.std.c, n.trees=5000)

profit.boost2 <- cumsum(14.5*c.valid[order(post.valid.boost, decreasing=T)]-2)
plot(profit.boost2) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.boost2) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.boost2)) # report number of mailings and maximum profit
# 1242  11871

cutoff.boost2 <- sort(post.valid.boost2, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.boost2 <- ifelse(post.valid.boost2>cutoff.boost2, 1, 0) # mail to everyone above the cutoff
table(chat.valid.boost2, c.valid) # classification table

#           c.valid
#       chat.valid.boost   0    1
#                       0 767   9
#                       1 252   990
# check n.mail.valid = 252 + 990 = 1242
# check profit = 14.5*990-2*1242 = 11871

# Support vector machine

set.seed(27)
model.svm=svm(donr~., data=data.train.std.c, kernel="radial",  gamma=1, cost=1)
plot(model.svm, data.train.std.c)

tune.out=tune(svm, donr~., data=data.train.std.c, kernel="radial", ranges=list(cost=c(0.1,1,10,100,1000),gamma=c(0.5,1,2,3,4)))
summary(tune.out$best.model)

post.valid.svm <- predict(tune.out$best.model,newdata=data.valid.std.c)

profit.svm <- cumsum(14.5*c.valid[order(post.valid.svm, decreasing=T)]-2)
plot(profit.svm) # see how profits change as more mailings are made
n.mail.valid <- which.max(profit.svm) # number of mailings that maximizes profits
c(n.mail.valid, max(profit.svm)) # report number of mailings and maximum profit
# 1023 10192

cutoff.svm <- sort(post.valid.svm, decreasing=T)[n.mail.valid+1] # set cutoff based on n.mail.valid
chat.valid.svm <- ifelse(post.valid.tree>cutoff.svm, 1, 0) # mail to everyone above the cutoff
table(chat.valid.svm, c.valid) # classification table

#           c.valid
#     chat.valid.svm   0   1
#                   0 840 155
#                   1 179 844
# check n.mail.valid = 179 + 844 = 1023
# check profit = 14.5*844-2*1023 = 10192

# n.mail Profit  Model
# 1329   11624.5 LDA1
# 1291   11642.5 Log1
# 1270   11742.5 Bag1
# 1267   11748.5 Bag2
# 1940   10576.5 Tree
# 1284   11845   Boost
# 1242   11871   Boost2
# 1023   10192   Support Vector Machine

# select model.boost2 since it has maximum profit in the validation sample
post.test <- predict(model.boost2, data.test.std, n.trees = 5000) # post probs for test data

# Oversampling adjustment for calculating number of mailings for test set

n.mail.valid <- which.max(profit.log1)
tr.rate <- .1 # typical response rate is .1
vr.rate <- .5 # whereas validation response rate is .5
adj.test.1 <- (n.mail.valid/n.valid.c)/(vr.rate/tr.rate) # adjustment for mail yes
adj.test.0 <- ((n.valid.c-n.mail.valid)/n.valid.c)/((1-vr.rate)/(1-tr.rate)) # adjustment for mail no
adj.test <- adj.test.1/(adj.test.1+adj.test.0) # scale into a proportion
n.mail.test <- round(n.test*adj.test, 0) # calculate number of mailings for test set

cutoff.test <- sort(post.test, decreasing=T)[n.mail.test+1] # set cutoff based on n.mail.test
chat.test <- ifelse(post.test>cutoff.test, 1, 0) # mail to everyone above the cutoff
table(chat.test)
#    0    1 
# 1676  331
# based on this model we'll mail to the 331 highest posterior probabilities

# See below for saving chat.test into a file for submission



##### PREDICTION MODELING ######

# Least squares regression

model.ls1 <- lm(damt ~ reg1 + reg2 + reg3 + reg4 + home + chld + hinc + genf + wrat + 
                  avhv + incm + inca + plow + npro + tgif + lgif + rgif + tdon + tlag + agif, 
                data.train.std.y)

pred.valid.ls1 <- predict(model.ls1, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.ls1)^2) # mean prediction error
# 1.867523
sd((y.valid - pred.valid.ls1)^2)/sqrt(n.valid.y) # std error
# 0.1696615

# drop wrat for illustrative purposes
model.ls2 <- lm(damt ~ reg1 + reg2 + reg3 + reg4 + chld + hinc + 
                  avhv + incm + inca + plow + npro + tgif + lgif + rgif + agif, 
                data.train.std.y)

pred.valid.ls2 <- predict(model.ls2, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.ls2)^2) # mean prediction error
# 1.864044
sd((y.valid - pred.valid.ls2)^2)/sqrt(n.valid.y) # std error
# 0.1690677

# Tree based
library(MASS)
set.seed(27)
tree.model=tree(damt~.,data.train.std.y)
summary(tree.model)
plot(tree.model)
text(tree.model,pretty=0)
cv.tree=cv.tree(tree.model)
plot(cv.tree$size,cv.tree$dev,type='b')
model.prune=prune.tree(tree.model,best=7)
plot(model.prune)
text(model.prune,pretty=0)

pred.valid.tree <- predict(model.prune, newdata = data.valid.std.y) # validation predictions
mean((y.valid - pred.valid.tree)^2) # mean prediction error
# 2.378834
sd((y.valid - pred.valid.tree)^2)/sqrt(n.valid.y) # std error
# 0.1868944

# Ridge regression
set.seed(27)
x<-data.train.std.y
y<-as.matrix(subset(data.train.std.y, select=-damt))
data.valid.cor.y<-as.matrix(data.valid.std.y)

grid=10^seq(10,-2,length=100)
model.lasso = glmnet(y,y.train,alpha=1,lambda = grid)

set.seed(1)
cv.out=cv.glmnet(y,y.train,alpha=1,lambda = grid)
bestlam=cv.out$lambda.min
lasso.pred=predict(model.lasso,s=bestlam,newx=data.valid.cor.y)

mean((y.valid - ridge.pred)^2) # mean prediction error
# 2.378834
sd((y.valid -ridge.pred)^2)/sqrt(n.valid.y) # std error
# 0.1868944


# Best subset selection
predict.regsubsets=function(object,newdata,id,...){
  form=as.formula(object$call[[2]])
  mat=model.matrix(form,newdata)
  coefi=coef(object,id=id)
  xvars=names(coefi)
  mat[,xvars]%*%coefi
}

set.seed(27)
k=10
folds=sample(1:k,nrow(data.train.std.y),replace=TRUE)
cv.errors=matrix(NA,k,10, dimnames=list(NULL, paste(1:10)))
set.seed(27)
for(j in 1:k){
  best.fit=regsubsets(damt~.,data=data.train.std.y[folds!=j,],nvmax=10)
  for(i in 1:10){
    pred=predict(best.fit,data.train.std.y[folds==j,],id=i)
    cv.errors[j,i]=mean( (data.train.std.y$damt[folds==j]-pred)^2)
  }
}
mean.cv.errors=apply(cv.errors,2,mean)
mean.cv.errors
par(mfrow=c(1,1))
plot(mean.cv.errors,type='b')
reg.best.cv=regsubsets(damt~.,data=data.train.std.y, nvmax=6)
coef(reg.best.cv,6)

pred.bestselect.model = predict(reg.best.cv,data.valid.std.y,6)

mean((y.valid - pred.bestselect.model)^2) # mean prediction error
# 1.980266
sd((y.valid - pred.bestselect.model)^2)/sqrt(n.valid.y) # std error
# 0.1688628

#  Bagging
set.seed(27)
model.bag.damt = randomForest(damt~.,data=data.train.std.y, mtry=20,importance=TRUE)
model.bag.damt

pred.bagdamt = predict(model.bag.damt,data.valid.std.y)

mean((y.valid - pred.bagdamt)^2) # mean prediction error
# 1.711844
sd((y.valid - pred.bagdamt)^2)/sqrt(n.valid.y) # std error
# 0.1750859

#  Random Forest
set.seed(27)
model.rf = randomForest(damt~.,data=data.train.std.y,mtry=5,importance=TRUE)
pred.rf=predict(model.rf,newdata=data.valid.std.y)

mean((y.valid - pred.rf)^2) # mean prediction error
# 1.666401
sd((y.valid - pred.rf)^2)/sqrt(n.valid.y) # std error
# 0.1733991

#Boosting
set.seed(27)
model.boostdamt=gbm(damt~.,data=data.train.std.y,distribution="gaussian",n.trees=5000,interaction.depth=4)

post.valid.boostdamt <- predict(model.boostdamt, data.valid.std.y, n.trees=5000)

mean((y.valid - post.valid.boostdamt)^2) # mean prediction error
# 1.539542
sd((y.valid - post.valid.boostdamt)^2)/sqrt(n.valid.y) # std error
# 0.1667702

# Results

#   MPE       Model
# 1.867523    LS1
# 1.867433    LS2
# 2.378834    Tree
# 1.980266    Best subset selection
# 1.711844    Bagging
# 1.666401    Random forest
# 1.539542    Boosting



# select model.ls2 since it has minimum mean prediction error in the validation sample

yhat.test <- predict(model.boostdamt, newdata = data.test.std,n.trees=5000) # test predictions




# FINAL RESULTS

# Save final results for both classification and regression

length(chat.test) # check length = 2007
length(yhat.test) # check length = 2007
chat.test[1:10] # check this consists of 0s and 1s
yhat.test[1:10] # check this consists of plausible predictions of damt

ip <- data.frame(chat=chat.test, yhat=yhat.test) # data frame with two variables: chat and yhat
write.csv(ip, file="CJP.csv", row.names=FALSE) # use your initials for the file name

# submit the csv file in Canvas for evaluation based on actual test donr and damt values
